{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.712066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  10000.000000\n",
       "mean       4.764600\n",
       "std        0.712066\n",
       "min        1.000000\n",
       "25%        5.000000\n",
       "50%        5.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# menampilkan info deskripsi dataset\n",
    "data_review.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil deskripsi review data, yang berjumlah 10.000 memiliki standard deviasi  0,71. Standar deviasi merupakan akar dari varian, sehingga semakin besar nilai standar deviasi maka data sampel semakin menyebar (bervariasi) dari rata-ratanya. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   label     10000 non-null  int64 \n",
      " 1   text      10000 non-null  object\n",
      " 2   Sentimen  10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# menampilkan info dataset\n",
    "data_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of duplicate reviews on train data: 0\n"
     ]
    }
   ],
   "source": [
    "#memeriksa duplicate data\n",
    "data_duplicate = data_review[data_review['text'].duplicated()]\n",
    "print(f'No. of duplicate reviews on train data: {data_duplicate.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data yang digunakan sudah terbilang baik, karena tidak terdapat data yang memiliki duplikat dan tidak ada data yang bernilai null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra Pemrosesan teks dilakukan untuk menghilangkan data yang tidak dibutuhkan ataupun data yang terdapat dalam teks yang tidak sesuai dengan proses yang dibutuhkan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(review):\n",
    "    for i in range(len(review)):\n",
    "        text = review.text.iloc[i]\n",
    "        for sent in nltk.sent_tokenize(text):\n",
    "            for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "                if hasattr(chunk, 'label') and chunk.label:\n",
    "                    if chunk.label() == 'ORGANIZATION' or  chunk.label() == 'PERSON' or  chunk.label() == 'DATE' or  chunk.label() == 'LOCATION':\n",
    "                        name_value = ' '.join(child[0] for child in chunk.leaves())\n",
    "                        text = text.replace(name_value, \"\")\n",
    "                        review.text.iloc[i] = text\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER (Named-Entity Recognition) digunakan untuk mencari dan mengelompokkan entitas dalam teks ke dalam kategori yang ditetapkan, misalnya nama orang, organisasi, lokasi, ekspresi, dll. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_folding(review):\n",
    "    for i in range(len(review)):\n",
    "        text = review.text[i].lower()\n",
    "        review.text.iloc[i] = text \n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case folding digunakan untuk mengkonversi keseluruhan teks huruf kapital (uppercase) pada sebuah kalimat menjadi huruf kecil (lowercase) serta menghilangkan seluruh karakter yang dianggap tidak valid seperti angka, tanda baca, dan Uniform Resources Locator (URL). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(review):\n",
    "    remove = string.punctuation\n",
    "    for i in range(len(review)):\n",
    "        for kata in remove:\n",
    "            text = review.text[i].replace(kata,\"\")\n",
    "            review.text.iloc[i] = text \n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation digunakan untuk menghapus semua tanda baca dari string atau ulasan pelanggan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_removal(review):\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    cachedStopWords = set(stopwords.words(\"english\"))\n",
    "    for i in range(len(review)):\n",
    "        text = review.text.iloc[i]\n",
    "        teks =\" \".join([word for word in text.split() if word not in cachedStopWords])\n",
    "        review.text.iloc[i] = teks\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords removal bertujuan untuk mengurangi kata yang kurang penting, seperti kata yang, di, ke, dalam, dan, dengan, ini, itu, untuk, dan lain sebagainya, sehingga mempermudah dan mempercepat pengolahan dokumen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(review):\n",
    "    ps = PorterStemmer()\n",
    "    for i in range(len(review)):\n",
    "        text = review.text.iloc[i]\n",
    "        text = ps.stem(text)\n",
    "        review.text.iloc[i] = text\n",
    "    return review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming digunakan untuk menghilangkan imbuhan-imbuhan seperti awalan kata (prefixes), sisipan kata (infixes), akhiran kata (suffixes) serta awalan dan akhiran kata (confixes) pada kata turunan. yang terdapat dalam kata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization (review):\n",
    "    lm = WordNetLemmatizer()\n",
    "    for i in range(len(review)):\n",
    "        text = review.text.iloc[i]\n",
    "        text = lm.lemmatize(text)\n",
    "        review.text.iloc[i] = text\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(review):\n",
    "    hasil_ner = NER(review)\n",
    "    hasil_case_folding = case_folding(hasil_ner)\n",
    "    hasil_remove_punctuation = NER(review)\n",
    "    hasil_stop_removal = stop_removal(hasil_remove_punctuation)\n",
    "    hasil_stemming = stemming( hasil_stop_removal)\n",
    "    hasil_lemmatization = lemmatization(hasil_stemming)\n",
    "    return hasil_lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada program berikut merupakan penerapan semua fungsi pemrosesan data yang telah didefinisikan sebelumnya. Hasil yang akan ditampilkan adalah hasil lematisasi karena lematisasi adalah proses terakhir yang menampung seluruh output tahap-tahap sebelumnya kemudian kemudian menjadi input tahap lematisasi lalu diproses dan menghasilkan output yaitu hasil dari tahap lematisasi tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Pebri Sangmajadi\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Pebri\n",
      "[nltk_data]     Sangmajadi S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Pebri Sangmajadi\n",
      "[nltk_data]     S\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pebri Sangmajadi S\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "clean_data = preprocessing_data(data_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pebri Sangmajadi S\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>Sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>looks ok  like durable  use recommend others w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>tried  current powerful depending setting  dar...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>received week  looks smaller expected  can t w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>thanks    works describe complaints  really ex...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fast delivery considering it s overseas tried ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>fast delivery good servic</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>got order came well packaged  yet try looks go...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>items received nice box  used yet  hopefully w...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>received good condition  tried far good  bad</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>item doesn t work   asked send refund   show n...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  Sentimen\n",
       "0      5  looks ok  like durable  use recommend others w...  Positive\n",
       "1      5  tried  current powerful depending setting  dar...  Positive\n",
       "2      5  received week  looks smaller expected  can t w...  Positive\n",
       "3      5  thanks    works describe complaints  really ex...  Positive\n",
       "4      5  fast delivery considering it s overseas tried ...  Positive\n",
       "5      5                          fast delivery good servic  Positive\n",
       "6      5  got order came well packaged  yet try looks go...  Positive\n",
       "7      5  items received nice box  used yet  hopefully w...  Positive\n",
       "8      5      received good condition  tried far good  bad   Positive\n",
       "9      1  item doesn t work   asked send refund   show n...  Negative"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern=r'[^a-zA-Z]'\n",
    "\n",
    "for i in range(len(clean_data)):\n",
    "    clean_data['text'].iloc[i] = re.sub(pattern,' ', clean_data['text'].iloc[i], flags=re.MULTILINE)\n",
    "clean_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perintah di atas bertujuan untuk menampilkan data hasil preprocessing yang sudah dilakukan sebelumnya. Berdasarkan hasil preprocessing telah didapatkan data yang sudah bersih, data hasi pra pemrosesan selanjutnya akan disimpan ke file baru yaitu file dengan format excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       looks ok  like durable  use recommend others w...\n",
       "1       tried  current powerful depending setting  dar...\n",
       "2       received week  looks smaller expected  can t w...\n",
       "3       thanks    works describe complaints  really ex...\n",
       "4       fast delivery considering it s overseas tried ...\n",
       "                              ...                        \n",
       "9995                          hi product work properly   \n",
       "9996    best purchase ever   never regret item came me...\n",
       "9997                  suction good  fall  happy purchase \n",
       "9998              goooood suction fast delivery   appreci\n",
       "9999                received good condition  yet try out \n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_preprocessing= data_review.to_excel('data_setelah_preprocessing.xlsx', encoding='utf-8')\n",
    "new_data = pd.read_excel('./data_setelah_preprocessing.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
